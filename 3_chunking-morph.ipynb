{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask import delayed\n",
    "from tqdm import tqdm\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Polygon\n",
    "import libpysal\n",
    "import pandas as pd\n",
    "from libpysal.weights import W\n",
    "import momepy\n",
    "import pickle\n",
    "import contextily as ctx\n",
    "from shapely.wkb import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "place = \"glasgow\"\n",
    "local_crs = 27700\n",
    "latlng = (-4.251846930489373, 55.86421405612109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daskCluster = LocalCluster(threads_per_worker=2,\n",
    "                n_workers=8, memory_limit='70GB')\n",
    "\n",
    "client = Client(daskCluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation = pd.read_parquet(f\"./output/{place}/tessellation_p1.pq\",engine='fastparquet')\n",
    "tessellation['geometry'] = tessellation['geometry'].apply(lambda x: loads(x) if x else None)\n",
    "tessellation = gpd.GeoDataFrame(tessellation, geometry=\"geometry\").set_crs(local_crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = gpd.read_parquet(f\"./output/{place}/buildings_p1.pq\").to_crs(local_crs)\n",
    "rail = gpd.read_parquet(f\"./output/{place}/rail_raw.pq\").to_crs(local_crs).reset_index(drop=True)\n",
    "streets = gpd.read_parquet(f\"./output/{place}/streets_raw.pq\").to_crs(local_crs).explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_area = gpd.read_parquet(f\"./output/{place}/study_area.pq\").to_crs(local_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[~buildings.geom_type.eq('Polygon')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[buildings[\"uID\"] == 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.geom_type.eq('Polygon').all()\n",
    "buildings[~buildings.geom_type.eq('Polygon')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.is_valid.eq('Polygon').all()\n",
    "tessellation[~tessellation.geom_type.eq('Polygon')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your GeoDataFrame\n",
    "gdf = tessellation\n",
    "\n",
    "# Calculate the extent of the dataset\n",
    "bounds = gdf.total_bounds  # [minx, miny, maxx, maxy]\n",
    "\n",
    "# Modify the create_grid function to include tqdm\n",
    "def create_grid(bounds, width, height):\n",
    "    minx, miny, maxx, maxy = bounds\n",
    "    grid = []\n",
    "    x_range = range(int((maxx - minx) / width)+1)\n",
    "    y_range = range(int((maxy - miny) / height)+1)\n",
    "\n",
    "    for x in tqdm(x_range, desc=\"Creating Grid\"):\n",
    "        x_coord = minx + x * width\n",
    "        for y in y_range:\n",
    "            y_coord = miny + y * height\n",
    "            grid.append(box(x_coord, y_coord, x_coord + width, y_coord + height))\n",
    "\n",
    "    return grid\n",
    "\n",
    "grid_squares = create_grid(bounds, 5000, 5000) \n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "grid_gdf = gpd.GeoDataFrame(geometry=grid_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example: Assuming gdf is your GeoDataFrame\n",
    "# gdf = gpd.read_file('your_file.geojson') or any other source\n",
    "\n",
    "# Get the total bounds\n",
    "bounds = gdf.total_bounds\n",
    "\n",
    "# Create a polygon from the bounds\n",
    "# The order of points is: bottom-left, top-left, top-right, bottom-right\n",
    "polygon = Polygon([(bounds[0], bounds[1]), (bounds[0], bounds[3]), \n",
    "                   (bounds[2], bounds[3]), (bounds[2], bounds[1])])\n",
    "\n",
    "# Optional: Plotting\n",
    "fig, ax = plt.subplots()\n",
    "x,y = polygon.exterior.xy\n",
    "plt.plot(x, y)\n",
    "plt.fill(x, y, alpha=0.3)\n",
    "grid_gdf.plot(ax=ax, color='red', alpha=0.2, edgecolor='black')\n",
    "tessellation[tessellation[\"uID\"] == 0].geometry.centroid.plot(ax=ax, alpha = 0.3)\n",
    "ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=tessellation.crs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gdf.to_parquet(f\"output/{place}/grid_gdf.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gdf[\"uID\"] = grid_gdf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbours(tessellation, cell):\n",
    "    # Get 'not disjoint' countries\n",
    "    neighbours = tessellation[~tessellation.geometry.disjoint(cell.geometry)].uID.tolist()\n",
    "    # Remove own uID of the cell from the list\n",
    "    neighbours_list = [uID for uID in neighbours if cell.uID != uID]\n",
    "    return neighbours_list\n",
    "\n",
    "out = []\n",
    "\n",
    "for index, cell in grid_gdf.iterrows():\n",
    "    # Add the delayed task to the current batch\n",
    "    result = find_neighbours(grid_gdf, cell)\n",
    "    out.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gdf[\"touching\"] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate centroids\n",
    "tessellation['centroid'] = tessellation.geometry.centroid\n",
    "\n",
    "# Step 2: Convert centroids to a new GeoDataFrame\n",
    "centroids = gpd.GeoDataFrame(tessellation, geometry='centroid')\n",
    "\n",
    "# Step 3: Perform spatial join\n",
    "joined_gdf = gpd.sjoin(centroids, grid_gdf, how='inner', op='intersects')\n",
    "\n",
    "# Step 4: Group original polygons based on the join\n",
    "grouped_gdf = tessellation.merge(joined_gdf[['centroid', 'index_right']], left_on='centroid', right_on='centroid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have a GeoDataFrame 'grouped_gdf' and you're grouping by some column 'grouping_column'\n",
    "grouped = grouped_gdf.groupby('index_right')\n",
    "\n",
    "cells_in_region = {region:set() for region in grid_gdf.uID}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the uID lists for each group\n",
    "for group_name, group in grouped:\n",
    "    cells_in_region[group_name] = set(group['uID'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'grouped_gdf' is your GeoDataFrame and it's correctly defined\n",
    "buffered_tessellation = grouped_gdf.copy()  # Create a copy to retain the original data\n",
    "\n",
    "# Apply a buffer of 50 units to each geometry\n",
    "buffered_tessellation[\"geometry\"] = buffered_tessellation[\"geometry\"].buffer(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_in_expanded_region = cells_in_region.copy()\n",
    "\n",
    "for index, region in tqdm(grid_gdf.iterrows(), total=grid_gdf.shape[0]):\n",
    "    expanded_cells = buffered_tessellation[buffered_tessellation['index_right'].isin(region.touching)]\n",
    "\n",
    "    intersection_rows = expanded_cells[expanded_cells.intersects(region.geometry.boundary)]\n",
    "    \n",
    "    cells_in_expanded_region[index] = cells_in_region[index].union(set(intersection_rows.uID.tolist()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'grouped_gdf' is your GeoDataFrame and it's correctly defined\n",
    "buffered_tessellation_200 = grouped_gdf.copy()  # Create a copy to retain the original data\n",
    "\n",
    "# Apply a buffer of 50 units to each geometry\n",
    "buffered_tessellation_200[\"geometry\"] = buffered_tessellation[\"geometry\"].buffer(250)\n",
    "\n",
    "cells_in_expanded_region_200 = cells_in_region.copy()\n",
    "\n",
    "for index, region in tqdm(grid_gdf.iterrows(), total=grid_gdf.shape[0]):\n",
    "    expanded_cells = buffered_tessellation_200[buffered_tessellation_200['index_right'].isin(region.touching)]\n",
    "\n",
    "    intersection_rows = expanded_cells[expanded_cells.intersects(region.geometry.boundary)]\n",
    "    \n",
    "    cells_in_expanded_region_200[index] = cells_in_region[index].union(set(intersection_rows.uID.tolist()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_weights = []\n",
    "\n",
    "for index, expanded_region in tqdm(grid_gdf.iterrows(), total=grid_gdf.shape[0]):\n",
    "    expanded_cell_gdf = tessellation[tessellation['uID'].isin(list(cells_in_expanded_region[index]))] \n",
    "    list_of_weights.append(libpysal.weights.fuzzy_contiguity(expanded_cell_gdf, tolerance=0.05, buffering=True, drop=True, buffer=5, ids=\"uID\", silence_warnings=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjlist_combined = None\n",
    "for index, weight in tqdm(enumerate(list_of_weights), total= len(list_of_weights)):\n",
    "    \n",
    "    adjlist = list_of_weights[index].to_adjlist()\n",
    "    \n",
    "    if index == 0:\n",
    "        adjlist_combined = adjlist\n",
    "    \n",
    "    else:\n",
    "        adjlist_combined = pd.concat([adjlist_combined, adjlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = tessellation['uID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uID_neighbours = {uID: set() for uID in unique_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in adjlist_combined.iterrows():\n",
    "    uID_neighbours[row[\"focal\"]].add(row[\"neighbor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_queen_region = {}\n",
    "for region in tqdm(cells_in_region):\n",
    "    cells_to_search = cells_in_region[region]\n",
    "    output = cells_in_region[region]\n",
    "    for i in range(5):\n",
    "        cells_found_in_current_iteration = set()\n",
    "        \n",
    "        for cell in cells_to_search:\n",
    "            cells_found_in_current_iteration = cells_found_in_current_iteration.union(uID_neighbours[cell])\n",
    "        \n",
    "        cells_to_search = cells_found_in_current_iteration.difference(output)\n",
    "        \n",
    "        output = output.union(cells_found_in_current_iteration)\n",
    "        \n",
    "    three_queen_region[region] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_gdf2 = tessellation[tessellation['uID'].isin(cells_in_region[ceil(len(three_queen_region)/2)])]\n",
    "filtered_gdf = tessellation[tessellation['uID'].isin(three_queen_region[ceil(len(three_queen_region)/2)])]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the first GeoDataFrame\n",
    "\n",
    "\n",
    "# Plot the second GeoDataFrame\n",
    "\n",
    "\n",
    "filtered_gdf.plot(ax=ax, color='red', edgecolor='k', alpha=1)\n",
    "\n",
    "filtered_gdf2.plot(ax=ax, color='green', edgecolor='k', alpha=1)\n",
    "\n",
    "\n",
    "# Customize the plot (optional)\n",
    "ax.set_title(\"Overlay of filtered_gdf and cells_in_region\")\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"output/{place}/three_queen_region.pq\", 'wb') as file:\n",
    "    pickle.dump(three_queen_region, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphometrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Weights\n",
    "buildings_local_out_combined = pd.DataFrame()\n",
    "buildings_dist200_combined = pd.DataFrame()\n",
    "tessellation_out_combined = pd.DataFrame()\n",
    "\n",
    "for cell_index in tqdm(three_queen_region):\n",
    "    print(\"new cell\", cell_index)\n",
    "    \n",
    "    if buildings[buildings['uID'].isin(three_queen_region[cell_index])].empty:\n",
    "        continue\n",
    "    \n",
    "    filtered_df = adjlist_combined[\n",
    "            adjlist_combined['focal'].isin(three_queen_region[cell_index]) & \n",
    "            adjlist_combined['neighbor'].isin(three_queen_region[cell_index])\n",
    "        ]\n",
    "    buildings_dist200 = buildings[buildings[\"uID\"].isin(cells_in_expanded_region_200)]\n",
    "    \n",
    "    queen_1 = W.from_adjlist(filtered_df)\n",
    "\n",
    "    queen_3 = momepy.sw_high(k=3, weights=queen_1)\n",
    "\n",
    "    dist200 = libpysal.weights.DistanceBand.from_dataframe(buildings_dist200, 200, ids='uID')\n",
    "    \n",
    "    buildings_local = buildings[buildings['uID'].isin(three_queen_region[cell_index])]\n",
    "\n",
    "    buildings_dist200[\"buildings_neighbours_200\"] = momepy.Neighbors(buildings_dist200, dist200, 'uID', weighted=True).series\n",
    "\n",
    "    buildings_out = buildings[buildings[\"uID\"].isin(cells_in_region[cell_index])]\n",
    "    \n",
    "    queen_3_adjlist = queen_3.to_adjlist()\n",
    "\n",
    "    # Get unique values from both columns\n",
    "    unique_focal = queen_3_adjlist['focal'].unique()\n",
    "    unique_neighbor = queen_3_adjlist['neighbor'].unique()\n",
    "\n",
    "    # Combine and get unique values across both columns\n",
    "    all_unique_values = pd.unique(pd.concat([pd.Series(unique_focal), pd.Series(unique_neighbor)]))\n",
    "    \n",
    "    tessellation_out = tessellation[tessellation[\"uID\"].isin(all_unique_values)]\n",
    "    \n",
    "    ### Building Area\n",
    "    buildings_local['building_area'] = momepy.Area(buildings_local).series\n",
    "    tessellation_out['tess_area'] = momepy.Area(tessellation_out).series\n",
    "    \n",
    "    tessellation_out[\"tessellation_neighbours\"] = momepy.Neighbors(tessellation_out, queen_3, 'uID', weighted=True).series\n",
    "    \n",
    "    buildings_local_scattered = client.scatter(buildings_local)\n",
    "    streets_scattered = client.scatter(streets)\n",
    "    tessellation_scattered = client.scatter(tessellation_out)\n",
    "\n",
    "    dist200_scattered = client.scatter(dist200)\n",
    "    queen_1_scattered = client.scatter(queen_1)\n",
    "    queen_3_scattered = client.scatter(queen_3)\n",
    "    \n",
    "    buildings_local_out = buildings_local\n",
    "    \n",
    "    # Assuming buildings_local_scattered is a GeoDataFrame and queen_1 is defined\n",
    "    \n",
    "    jobs_names = ['building_circular_compactness', 'building_elongation', 'building_squareness', 'building_eri', 'building_orientation', \"building_neighbour_dist\", \"building_neighbourhood_interbuilding_distance\"]\n",
    "\n",
    "    jobs = [dask.delayed(momepy.CircularCompactness)(buildings_local_scattered), \n",
    "            dask.delayed(momepy.Elongation)(buildings_local_scattered), \n",
    "            dask.delayed(momepy.Squareness)(buildings_local_scattered),\n",
    "            dask.delayed(momepy.EquivalentRectangularIndex)(buildings_local_scattered), \n",
    "            dask.delayed(momepy.Orientation)(buildings_local_scattered), \n",
    "            dask.delayed(momepy.NeighborDistance)(buildings_local_scattered, queen_1_scattered, 'uID'), \n",
    "            dask.delayed(momepy.MeanInterbuildingDistance)(buildings_local_scattered, queen_1_scattered, 'uID', 3)]\n",
    "\n",
    "    jobs_out = dask.compute(jobs)\n",
    "\n",
    "    # Assign the results back to the buildings_local GeoDataFrame\n",
    "    for index, field_name in enumerate(jobs_names):\n",
    "        buildings_local_out[field_name] = jobs_out[0][index].series\n",
    "        \n",
    "    buildings_local_scattered = client.scatter(buildings_local_out)\n",
    "\n",
    "    # Assuming buildings_local_scattered is a GeoDataFrame and queen_1 is defined\n",
    "\n",
    "    jobs_names = [\"tess_convexity\", \"tess_covered_area\", \"tess_orientation\"]\n",
    "\n",
    "    jobs = [dask.delayed(momepy.Convexity)(tessellation_scattered), \n",
    "            dask.delayed(momepy.CoveredArea)(tessellation_scattered, queen_1_scattered, \"uID\"),\n",
    "            dask.delayed(momepy.Orientation)(tessellation_scattered)]\n",
    "\n",
    "    jobs_out = dask.compute(jobs)\n",
    "\n",
    "    # Assign the results back to the buildings_local GeoDataFrame\n",
    "    for index, field_name in enumerate(jobs_names):\n",
    "        tessellation_out[field_name] = jobs_out[0][index].series\n",
    "\n",
    "    tessellation_scattered = client.scatter(tessellation_out)\n",
    "    \n",
    "    # Assuming buildings_local_scattered is a GeoDataFrame and queen_1 is defined\n",
    "\n",
    "    jobs_names = ['building_circular_compactness_weight', 'building_elongation_weight', 'building_squareness_weight', 'building_eri_weight', \"building_neighbour_dist_weight\", \"building_neighbourhood_interbuilding_distance_weight\", 'building_orientation_weight']\n",
    "\n",
    "    jobs = [dask.delayed(momepy.WeightedCharacter)(buildings_local_scattered,\n",
    "                                                            values='building_circular_compactness',\n",
    "                                                            spatial_weights=queen_3_scattered,\n",
    "                                                            unique_id='uID'),\n",
    "            dask.delayed(momepy.WeightedCharacter)(buildings_local_scattered,\n",
    "                                                            values='building_elongation',\n",
    "                                                            spatial_weights=queen_3_scattered,\n",
    "                                                            unique_id='uID'),\n",
    "            dask.delayed(momepy.WeightedCharacter)(buildings_local_scattered,\n",
    "                                                            values='building_squareness',\n",
    "                                                            spatial_weights=queen_3_scattered,\n",
    "                                                            unique_id='uID'),\n",
    "            dask.delayed(momepy.WeightedCharacter)(buildings_local_scattered,\n",
    "                                                            values='building_eri',\n",
    "                                                            spatial_weights=queen_3_scattered,\n",
    "                                                            unique_id='uID'),\n",
    "            dask.delayed(momepy.WeightedCharacter)(buildings_local_scattered,\n",
    "                                                            values='building_neighbour_dist',\n",
    "                                                            spatial_weights=queen_3_scattered,\n",
    "                                                            unique_id='uID'),\n",
    "            dask.delayed(momepy.WeightedCharacter)(buildings_local_scattered,\n",
    "                                                            values='building_neighbourhood_interbuilding_distance',\n",
    "                                                            spatial_weights=queen_3_scattered,\n",
    "                                                            unique_id='uID'),\n",
    "            dask.delayed(momepy.WeightedCharacter)(buildings_local_scattered,\n",
    "                                                            values='building_orientation',\n",
    "                                                            spatial_weights=queen_3_scattered,\n",
    "                                                            unique_id='uID')]\n",
    "\n",
    "    jobs_out = dask.compute(*jobs)\n",
    "\n",
    "    # Assign the results back to the buildings_local GeoDataFrame\n",
    "    for index, field_name in enumerate(jobs_names):\n",
    "        buildings_local_out[field_name] = jobs_out[index].series\n",
    "\n",
    "    buildings_local_scattered = client.scatter(buildings_local_out)\n",
    "    \n",
    "    # Assuming buildings_local_scattered is a GeoDataFrame and queen_1 is defined\n",
    "\n",
    "    jobs_names = [\"tess_convexity_weight\", \"tess_covered_area_weight\", \"tess_orientation_weight\", \"tess_rea_theil\", \"building_neighbourhood_interbuilding_distance_weight\"]\n",
    "\n",
    "    jobs = [dask.delayed(momepy.WeightedCharacter)(tessellation_scattered,\n",
    "                                                            values=\"tess_convexity\",\n",
    "                                                            spatial_weights=queen_3_scattered,\n",
    "                                                            unique_id='uID'),\n",
    "            dask.delayed(momepy.WeightedCharacter)(tessellation_scattered,\n",
    "                                                            values='tess_covered_area',\n",
    "                                                            spatial_weights=queen_3_scattered,\n",
    "                                                            unique_id='uID'),\n",
    "            dask.delayed(momepy.WeightedCharacter)(tessellation_scattered,\n",
    "                                                            values='tess_orientation',\n",
    "                                                            spatial_weights=queen_3_scattered,\n",
    "                                                            unique_id='uID'),\n",
    "            dask.delayed(momepy.Theil)(tessellation_scattered, values='tess_area', spatial_weights=queen_3_scattered, unique_id='uID'),\n",
    "            dask.delayed(momepy.WeightedCharacter)(buildings_local_scattered,\n",
    "                                                            values='building_neighbourhood_interbuilding_distance',\n",
    "                                                            spatial_weights=queen_3_scattered,\n",
    "                                                            unique_id='uID')]\n",
    "\n",
    "    jobs_out = dask.compute(*jobs)\n",
    "\n",
    "    # Assign the results back to the buildings_local GeoDataFrame\n",
    "    for index, field_name in enumerate(jobs_names):\n",
    "        if index == len(jobs_names) - 1:  # Check if it's the last iteration\n",
    "            buildings_local_out[field_name] = jobs_out[index].series\n",
    "        else:\n",
    "            tessellation_out[field_name] = jobs_out[index].series\n",
    "            \n",
    "    buildings_local_out.to_parquet(f\"output/{place}/momepy_building_local_out_part{cell_index}.pq\")\n",
    "    buildings_dist200.to_parquet(f\"output/{place}/momepy_building_dist200_out_part{cell_index}.pq\")\n",
    "    tessellation_out.to_parquet(f\"output/{place}/momepy_tessellation_out_part{cell_index}.pq\")\n",
    "    \n",
    "    buildings_local_out = buildings_local_out.drop('geometry', axis=1)\n",
    "    tessellation_out = tessellation_out.drop(['geometry', 'centroid'], axis=1)\n",
    "    buildings_dist200 = buildings_dist200.drop('geometry', axis=1)\n",
    "    \n",
    "    if cell_index == 0:\n",
    "        buildings_local_out_combined = buildings_local_out[buildings_local_out[\"uID\"].isin(cells_in_region[cell_index])]\n",
    "        buildings_dist200_combined = buildings_dist200[buildings_dist200[\"uID\"].isin(cells_in_region[cell_index])]\n",
    "        tessellation_out_combined = tessellation_out[tessellation_out[\"uID\"].isin(cells_in_region[cell_index])]\n",
    "    \n",
    "    else:\n",
    "        buildings_local_out_combined = pd.concat([buildings_local_out_combined, buildings_local_out[buildings_local_out[\"uID\"].isin(cells_in_region[cell_index])]], ignore_index=True)\n",
    "        buildings_dist200_combined = pd.concat([buildings_dist200_combined, buildings_dist200[buildings_dist200[\"uID\"].isin(cells_in_region[cell_index])]], ignore_index=True)\n",
    "        tessellation_out_combined = pd.concat([tessellation_out_combined, tessellation_out[tessellation_out[\"uID\"].isin(cells_in_region[cell_index])]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_local_out_combined.to_parquet(f\"output/{place}/buildings_dist200_out_combined.pq\")\n",
    "buildings_dist200_combined.to_parquet(f\"output/{place}/buildings_dist200_combined.pq\")\n",
    "tessellation_out_combined.to_parquet(f\"output/{place}/tessellation_out_combined.pq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuity = momepy.COINS(streets)\n",
    "\n",
    "stroke_attr = continuity.stroke_attribute()\n",
    "\n",
    "stroke_gdf = continuity.stroke_gdf()\n",
    "\n",
    "stroke_gdf.plot(stroke_gdf.length,\n",
    "                figsize=(15, 15),\n",
    "                cmap=\"viridis_r\",\n",
    "                linewidth=.5,\n",
    "                scheme=\"headtailbreaks\"\n",
    "               ).set_axis_off()\n",
    "\n",
    "stroke_gdf[\"length\"] = stroke_gdf.length\n",
    "\n",
    "stroke_gdf.to_parquet(f\"output/{place}/stroke_gdf.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buildings = gpd.GeoDataFrame(buildings.merge(buildings_local_out_combined, on='uID', how='inner').merge(buildings_dist200_combined, on='uID', how='inner'), crs=local_crs)\n",
    "buildings_out = gpd.GeoDataFrame(buildings.merge(buildings_local_out_combined, on='uID', how='inner'), crs=local_crs)\n",
    "tessellation_out = gpd.GeoDataFrame(tessellation.merge(tessellation_out_combined, on='uID', how='inner'), crs=local_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
